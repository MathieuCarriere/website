{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os \n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"\"\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Read data\n",
    "\n",
    "\n",
    "Persistence diagrams are assumed to be in .hdf5 file format with filtrations given as keys (i.e. \"alpha\", \"rips\"...) and homological dimensions given as sub-keys (i.e. \"0\", \"1\"...). These keys and sub-keys lead to a dictionnary, whose keys correspond to data indexes starting at 0. For instance, the 10th 0-dimensional persistence diagram computed with the rips filtration, which is an array of size (num_pts, 2), is accessed with data[\"rips\"][\"0\"][\"10\"].\n",
    "\n",
    "Features are given in .csv file format, with the first columns giving the targets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Provide names of different tasks (as in the corresponding .csv file)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tasks = [(\"topic\", \"classification\")]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read train data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_train_feat = \"../datasets/reddit/train.csv\"\n",
    "train_feat = pd.read_csv(path_to_train_feat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_train_diag = \"../datasets/reddit/train_diag.hdf5\"\n",
    "train_diag = diag_to_dict(h5py.File(path_to_train_diag, \"r\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Specify if test set is 1. a fraction of train set (False) / 2. a separate set with possibly missing labels (True)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_fraction_of_train_for_test = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If test set is fraction of training set, specify ratio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_size = 0.2\n",
    "\n",
    "if use_fraction_of_train_for_test == True:\n",
    "    train_num_pts = train_feat.shape[0]    \n",
    "    perm = np.random.permutation(train_num_pts)\n",
    "    limit = np.int(test_size * train_num_pts)\n",
    "    test_sub, train_sub = perm[:limit], perm[limit:] #np.sort(perm[:limit]), np.sort(perm[limit:])\n",
    "    train_num_pts, test_num_pts = len(train_sub), len(test_sub)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Else, read test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if use_fraction_of_train_for_test == False:\n",
    "    path_to_test_feat = \"../../../../Documents/datasets/bridge/7/train.csv\"\n",
    "    test_feat = pd.read_csv(path_to_test_feat)\n",
    "    train_num_pts, test_num_pts = train_feat.shape[0], test_feat.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if use_fraction_of_train_for_test == False:\n",
    "    path_to_test_diag = \"../../../../Documents/datasets/bridge/7/train_diag.hdf5\"\n",
    "    test_diag = diag_to_dict(h5py.File(path_to_test_diag, \"r\"))\n",
    "    filt = train_diag.keys()\n",
    "    train_num_pts, test_num_pts = len(train_diag[filt[0]]), len(test_diag[filt[0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert data frame into numpy array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_F = np.array(train_feat)[:,1+len(tasks):]\n",
    "num_features = train_F.shape[1]\n",
    "\n",
    "if use_fraction_of_train_for_test == False:\n",
    "    test_F = np.array(test_feat)[:,1+len(tasks):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_train_pred, list_test_pred, list_model = [], [], []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diag_example = tda.DiagramSelector(limit = np.inf, point_type = \"finite\").fit_transform(train_diag[\"0_degree\"])\n",
    "\n",
    "pre = tda.DiagramPreprocessor(use=True, scaler=MinMaxScaler()).fit(diag_example)\n",
    "[mx,my],[Mx,My] = pre.scaler.data_min_, pre.scaler.data_max_\n",
    "print(\"Minimum x = \" + str(mx) + \", Maximum x = \" + str(Mx) + \", Minimum y = \" + str(my) + \", Maximum y = \" + str(My))\n",
    "#[mx],[Mx] = pre.scaler.data_min_, pre.scaler.data_max_\n",
    "#print(\"Minimum x = \" + str(mx) + \", Maximum x = \" + str(Mx))\n",
    "max_card, min_card = 0, 1e10\n",
    "for i in range(len(diag_example)):\n",
    "    max_card, min_card = max(max_card, diag_example[i].shape[0]), min(min_card, diag_example[i].shape[0])\n",
    "print(\"Min cardinal = \" + str(min_card) + \", Max cardinal = \" + str(max_card))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_feat.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Model with Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reset vectors and size of train and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ratio, test_ratio = 1, 1\n",
    "print(\"Num train points = \" + str(len(np.arange(0,train_num_pts,train_ratio))))\n",
    "print(\"Num test points  = \" + str(len(np.arange(0,test_num_pts,test_ratio))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_name, task_type = tasks[0]\n",
    "\n",
    "train_full_labels = train_feat[task_name]\n",
    "if use_fraction_of_train_for_test == True:\n",
    "    train_labels = train_full_labels[train_sub][::train_ratio]\n",
    "    test_labels =  train_full_labels[test_sub][::test_ratio]\n",
    "else:\n",
    "    train_labels = train_full_labels[::train_ratio]\n",
    "    \n",
    "if task_type == \"classification\":\n",
    "    train_labels = np.array(LabelEncoder().fit_transform(train_labels))\n",
    "    if use_fraction_of_train_for_test == True:            \n",
    "        test_labels = np.array(LabelEncoder().fit_transform(test_labels))\n",
    "    \n",
    "print(\"Task: \" + task_name + \" \" + task_type + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_V, test_V = [], []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if use_fraction_of_train_for_test == True:\n",
    "    train_V.append(train_F[train_sub,:][::train_ratio,:])\n",
    "    test_V.append(train_F[test_sub,:][::test_ratio,:])\n",
    "else:\n",
    "    train_V.append(train_F[::train_ratio,:])\n",
    "    test_V.append(test_F[::test_ratio,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute vectorizations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorize_diagram = Pipeline([(\"Separator\",     tda.DiagramSelector(limit=np.inf, point_type=\"finite\")),\n",
    "                              (\"Rotator\",       tda.DiagramPreprocessor(scaler=tda.BirthPersistenceTransform())),\n",
    "                              (\"Vectorizer\",    tda.Landscape())])\n",
    "\n",
    "param   =  {\"Rotator__use\":            True,\n",
    "            \"Vectorizer\":              tda.PersistenceImage(), \n",
    "            \"Vectorizer__resolution\":  [30,30],\n",
    "            \"Vectorizer__bandwidth\":   0.01,\n",
    "            \"Vectorizer__weight\":      lambda x: x[1],\n",
    "            #\"Vectorizer__im_range\":    [0.0, 0.13, 0.0, 1.0]\n",
    "           }\n",
    "\n",
    "vectorize_diagram = vectorize_diagram.set_params(**param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diagram_types  = [\"0_handmade\"]\n",
    "\n",
    "for dt in diagram_types:\n",
    "    \n",
    "    train_full_D_i = vectorize_diagram.fit_transform(train_diag[dt])\n",
    "    np.save(dt, train_full_D_i)\n",
    "    \n",
    "    if use_fraction_of_train_for_test == True:\n",
    "        train_D_i = train_full_D_i[train_sub,:][::train_ratio,:]\n",
    "        test_D_i  = train_full_D_i[test_sub,:][::test_ratio,:]\n",
    "    else:\n",
    "        train_D_i = train_full_D_i[::train_ratio,:]\n",
    "        test_D_i  = vectorize_diagram.transform(test_diag[dt])[::test_ratio,:]\n",
    "    \n",
    "    train_V.append(train_D_i)\n",
    "    test_V.append(test_D_i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read vectorizations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paths = {\"train\": [#\"../../../../Documents/datasets/bridge/s3/train-0_alpha-PI-20-20-linear-5.npy\",\n",
    "                   #\"../../../../Documents/datasets/bridge/s3/train-1_alpha-PI-20-20-linear-5.npy\",\n",
    "                   \"../../../../Documents/datasets/bridge/s10/train-1_alpha-PI-20-20-linear-5.npy\"], \n",
    "         \"test\":  []}\n",
    "\n",
    "for i in range(len(paths[\"train\"])):\n",
    "    train_full_D_i = np.load(paths[\"train\"][i])\n",
    "    \n",
    "    if use_fraction_of_train_for_test == True:\n",
    "        train_D_i = train_full_D_i[train_sub,:][::train_ratio,:]\n",
    "        test_D_i  = train_full_D_i[test_sub,:][::test_ratio,:]\n",
    "    else:\n",
    "        train_D_i = train_full_D_i[::train_ratio,:]\n",
    "        test_D_i  = np.load(paths[\"test\"][i])[::test_ratio,:]\n",
    "        \n",
    "    train_V.append(train_D_i)\n",
    "    test_V.append(test_D_i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Concatenate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_V, test_V = np.concatenate(train_V, 1), np.concatenate(test_V, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train and test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predictor (sklearn, xgboost)\n",
    "if task_type == \"classification\":\n",
    "    list_of_feature_models = [(\"SVM\", SVC()),               \n",
    "                              (\"RF\", RandomForestClassifier()), \n",
    "                              (\"AB\", AdaBoostClassifier()), \n",
    "                              (\"XGB\", XGBClassifier())\n",
    "                             ]\n",
    "if task_type == \"regression\":\n",
    "    list_of_feature_models = [(\"RF\", RandomForestRegressor()), \n",
    "                              (\"AB\", AdaBoostRegressor()), \n",
    "                              (\"XGB\", XGBRegressor())\n",
    "                             ]\n",
    "\n",
    "#pre = hp.choice(\"pre\", [[], [pca(\"pre.pca\")]])\n",
    "#if task_type == \"classification\" or task_type == \"metric\":\n",
    "#    clf = hp.choice(\"clf\", [svc(\"clf.svc\"), xgboost_classification(\"clf.xgb\")])\n",
    "#    model = HyperoptEstimator(classifier = clf, preprocessing = pre)\n",
    "#    model = HyperoptEstimator(classifier = any_classifier(\"clf\"), preprocessing = any_preprocessing(\"pre\"))\n",
    "#if task_type == \"regression\":\n",
    "#    reg = hp.choice(\"reg\", [svr(\"reg.svr\"), xgboost_regression(\"reg.xgb\")])\n",
    "#    model = HyperoptEstimator(regressor = any_classifier(\"reg\"), preprocessing = any_preprocessing(\"pre\"))\n",
    "#    model = HyperoptEstimator(regressor = reg, preprocessing = pre)\n",
    "       \n",
    "for model_name, model in list_of_feature_models:        \n",
    "    \n",
    "    # Learning predictor\n",
    "    model.fit(train_V, train_labels)\n",
    "    list_model.append(model)\n",
    "\n",
    "    # Prediction\n",
    "    train_pred, test_pred = model.predict(train_V), model.predict(test_V)\n",
    "    list_train_pred.append(train_pred[:,np.newaxis])\n",
    "    list_test_pred.append(test_pred[:,np.newaxis])\n",
    "\n",
    "    # Save predictions\n",
    "    if use_fraction_of_train_for_test == False:\n",
    "        np.savetxt(task_name + \"-\" + model_name, test_pred)\n",
    "    \n",
    "    # Evaluation on train set\n",
    "    print(\"Train score of \" + model_name + \" = \" + str(model.score(train_V, train_labels)))\n",
    "    if task_type == \"regression\":\n",
    "        print(\"Train MSE of \" + model_name +\" = \" + str(mean_squared_error(train_pred, train_labels)))\n",
    "        \n",
    "    # Evaluation on test set\n",
    "    if use_fraction_of_train_for_test == True:\n",
    "            \n",
    "        print(\"Test score of \" + model_name + \" = \" + str(model.score(test_V, test_labels)))       \n",
    "        if task_type == \"regression\":\n",
    "            print(\"Test MSE of \" + model_name + \" = \" + str(mean_squared_error(test_pred, test_labels)))\n",
    "            plot_regression_result(test_labels, test_pred)\n",
    "        if task_type == \"classification\":\n",
    "            plot_confusion_matrix(confusion_matrix(test_labels, test_pred))\n",
    "        \n",
    "    print(\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "idx = 100\n",
    "plt.scatter(train_diag[\"0_handmade\"][train_sub[idx]][:,0], train_diag[\"0_handmade\"][train_sub[idx]][:,1])\n",
    "plt.show()\n",
    "plt.imshow(np.flip(np.reshape(train_V[idx,-900:], [30,30]), 0).astype(float))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_of_RF = 1\n",
    "fi = list_model[index_of_RF][1].feature_importances_\n",
    "plt.imshow(np.flip(np.reshape(fi[-900:], [30,30]), 0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Model with Kernels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reset kernel matrices and size of train and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ratio, test_ratio = 1, 1\n",
    "print(\"Num train points = \" + str(len(np.arange(0,train_num_pts,train_ratio))))\n",
    "print(\"Num test  points = \" + str(len(np.arange(0,test_num_pts,test_ratio))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_name, task_type = tasks[0]\n",
    "\n",
    "train_full_labels = train_feat[task_name]\n",
    "if use_fraction_of_train_for_test == True:\n",
    "    train_labels = train_full_labels[train_sub][::train_ratio]\n",
    "    test_labels =  train_full_labels[test_sub][::test_ratio]\n",
    "else:\n",
    "    train_labels = train_full_labels[::train_ratio]\n",
    "    \n",
    "if task_type == \"classification\":\n",
    "    train_labels = np.array(LabelEncoder().fit_transform(train_labels))\n",
    "    if use_fraction_of_train_for_test == True:            \n",
    "        test_labels = np.array(LabelEncoder().fit_transform(test_labels))\n",
    "    \n",
    "print(\"Task: \" + task_name + \" \" + task_type + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_M, test_M = [], []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add kernel on features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if train_F.shape[1] > 0:\n",
    "    if use_fraction_of_train_for_test == True:\n",
    "        train_M.append(pairwise_kernels(X = train_F[train_sub,:][::train_ratio], metric = \"rbf\")[np.newaxis,:])\n",
    "        test_M.append(pairwise_kernels(X = train_F[test_sub,:][::test_ratio], \n",
    "                                       Y = train_F[train_sub,:][::train_ratio], metric = \"rbf\")[np.newaxis,:])\n",
    "    else:\n",
    "        train_M.append(pairwise_kernels(X = train_F[::train_ratio], metric = \"rbf\")[np.newaxis,:])\n",
    "        test_M.append(pairwise_kernels(X = test_F[::test_ratio], \n",
    "                                       Y = train_F[::train_ratio], metric = \"rbf\")[np.newaxis,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Computation of kernels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernelize_diagram = Pipeline([(\"Separator\",  tda.DiagramSelector(limit=np.inf, point_type=\"finite\")),\n",
    "                              (\"Kernelizer\", tda.SlicedWasserstein())])\n",
    "\n",
    "param_kernel  = {\"Kernelizer\":                      tda.SlicedWasserstein(), \n",
    "                 \"Kernelizer__num_directions\":      10,\n",
    "                 \"Kernelizer__bandwidth\":           10.0,\n",
    "                }\n",
    "                    \n",
    "kernelize_diagram = kernelize_diagram.set_params(**param_kernel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diagram_types  = [\"1_alpha\"]\n",
    "\n",
    "for dt in diagram_types:\n",
    "    \n",
    "    train_full_K_i = kernelize_diagram.fit_transform(train_diag[dt])\n",
    "    np.save(dt, train_full_K_i)\n",
    "    \n",
    "    if use_fraction_of_train_for_test == True:\n",
    "        train_K_i = train_full_K_i[train_sub,:][:,train_sub][::train_ratio,:][:,::train_ratio]\n",
    "        test_K_i  = train_full_K_i[test_sub,:][:,train_sub][::test_ratio,:][:,::train_ratio]\n",
    "    else:\n",
    "        train_K_i = train_full_K_i[::train_ratio,:][:,::train_ratio]\n",
    "        test_K_i  = kernelize_diagram.transform(test_diag[dt])[::test_ratio,:][:,::train_ratio] \n",
    "    \n",
    "    train_M.append(train_K_i[np.newaxis,:])\n",
    "    test_M.append(test_K_i[np.newaxis,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reading of kernels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paths = {\"train\": [\"../../../../Documents/datasets/bridge/s3/train-1_alpha-SW-10-20.npy\"], \n",
    "         \"test\":  []}\n",
    "\n",
    "for i in range(len(paths[\"train\"])):\n",
    "    train_full_K_i = np.load(paths[\"train\"][i])\n",
    "    \n",
    "    if use_fraction_of_train_for_test == True:\n",
    "        train_K_i = train_full_K_i[train_sub,:][:,train_sub][::train_ratio,:][:,::train_ratio]\n",
    "        test_K_i  = train_full_K_i[test_sub,:][:,train_sub][::test_ratio,:][:,::train_ratio]\n",
    "    else:\n",
    "        train_K_i = train_full_K_i[::train_ratio,:][:,::train_ratio]\n",
    "        test_K_i  = np.load(paths[\"test\"][i])[::test_ratio,:][:,::train_ratio] \n",
    "    \n",
    "    train_M.append(train_K_i[np.newaxis,:])\n",
    "    test_M.append(test_K_i[np.newaxis,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Concatenate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_M, test_M = np.concatenate(train_M, 0), np.concatenate(test_M, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Learning and applying best kernel combination."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mkl = RMGD()\n",
    "\n",
    "if train_M.shape[0] == 1:\n",
    "    train_K, test_K = train_M[0,:,:], test_M[0,:,:]\n",
    "else:\n",
    "    if task_type == \"regression\":\n",
    "        hist, bin_edges    = np.histogram(train_labels)\n",
    "        train_targets_mkl  = np.digitize(train_labels, bin_edges)\n",
    "    if task_type == \"classification\":\n",
    "        train_targets_mkl  = train_labels\n",
    "    train_K = mkl.arrange_kernel(train_M, train_targets_mkl)\n",
    "    test_K  = np.average(test_M, axis=0, weights=mkl.weights)\n",
    "    print(mkl.weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train and test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predictor (sklearn)\n",
    "if task_type == \"classification\":\n",
    "    list_of_kernel_models = [(\"SVM\", SVC(kernel = \"precomputed\"))]\n",
    "if task_type == \"regression\":\n",
    "    list_of_kernel_models = [(\"SVM\", SVR(kernel = \"precomputed\")), (\"KR\", KernelRidge(kernel = \"precomputed\"))]\n",
    "\n",
    "#if task_type == \"classification\" or task_type == \"metric\":\n",
    "#    mod_list, param_mod = {\"SVM\": SVC()}, {\"SVM\": {\"kernel\": [\"precomputed\"]}}\n",
    "#if task_type == \"regression\":\n",
    "#    mod_list   = {\"SVM\": SVR(), \"Ridge\": KernelRidge()}\n",
    "#    param_mod  = {\"SVM\": {\"kernel\": [\"precomputed\"]}, \"Ridge\": {\"kernel\": [\"precomputed\"]}}\n",
    "#model = PredictorSelector(mod_list, param_mod)\n",
    "\n",
    "for model_name, model in list_of_kernel_models:\n",
    "\n",
    "    # Learning predictor\n",
    "    fn = model.fit(train_K, train_labels)\n",
    "    list_model.append(fn)\n",
    "\n",
    "    # Prediction\n",
    "    train_pred, test_pred = fn.predict(train_K), fn.predict(test_K)\n",
    "    list_train_pred.append(train_pred[:,np.newaxis])\n",
    "    list_test_pred.append(test_pred[:,np.newaxis])\n",
    "\n",
    "    # Save predictions\n",
    "    if use_fraction_of_train_for_test == False:\n",
    "        np.savetxt(task_name + \"-\" + model_name, test_pred)\n",
    "        \n",
    "    # Evaluation on train set\n",
    "    print(\"Train score of \" + model_name + \" = \" + str(fn.score(train_K, train_labels)))\n",
    "    if task_type == \"regression\":\n",
    "        print(\"Train MSE of \" + model_name + \" = \" + str(mean_squared_error(train_pred, train_labels)))\n",
    "    \n",
    "    # Evaluation on test set\n",
    "    if use_fraction_of_train_for_test == True:\n",
    "            \n",
    "        print(\"Test score of \" + model_name + \" = \" + str(fn.score(test_K, test_labels)))\n",
    "        if task_type == \"regression\":\n",
    "            print(\"Test MSE of \" + model_name + \" = \" + str(mean_squared_error(test_pred, test_labels)))\n",
    "            plot_regression_result(test_labels, test_pred)\n",
    "        if task_type == \"classification\" or task_type == \"metric\":\n",
    "            plot_confusion_matrix(confusion_matrix(test_labels, test_pred))\n",
    "            \n",
    "    print(\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Neural Net Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reset network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "tensorboard = False\n",
    "feed_train, feed_test, feed_epoch = dict(), dict(), dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_name, task_type = tasks[0]\n",
    "\n",
    "ohe, le = OneHotEncoder(sparse = False), LabelEncoder()\n",
    "\n",
    "train_full_labels = train_feat[task_name]\n",
    "if use_fraction_of_train_for_test == True:\n",
    "    train_labels = train_full_labels[train_sub]\n",
    "    test_labels =  train_full_labels[test_sub]\n",
    "else:\n",
    "    train_labels = train_full_labels\n",
    "    \n",
    "if task_type == \"classification\":\n",
    "    train_labels = ohe.fit_transform(np.reshape(le.fit_transform(train_labels), [-1,1]))\n",
    "    if use_fraction_of_train_for_test == True:            \n",
    "        test_labels = ohe.transform(np.reshape(le.transform(test_labels), [-1,1]))\n",
    "if task_type == \"regression\":\n",
    "    train_labels = np.reshape(train_labels, [-1,1])\n",
    "    if use_fraction_of_train_for_test == True:            \n",
    "        test_labels = np.reshape(test_labels, [-1,1])\n",
    "\n",
    "num_labels = train_labels.shape[1]\n",
    "with tf.device(\"/cpu:0\"):\n",
    "    label = tf.placeholder(tf.float32, shape = [None, num_labels], name = \"labels\")\n",
    "    \n",
    "feed_train[label] = train_labels\n",
    "if use_fraction_of_train_for_test == True:\n",
    "    feed_test[label] = test_labels\n",
    "    \n",
    "print(\"Task: \" + task_name + \" \" + task_type + \", \" + str(num_labels) + \" label(s)\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Input Diagrams\n",
    "\n",
    "Necessary preprocessing for tensorflow\n",
    "1. preprocess diagrams,\n",
    "2. pad diagrams with nans so that dimensions agree, \n",
    "3. compute masks i.e. locations of nans, \n",
    "4. replace nans with zeros,\n",
    "5. compute integer version of masks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diagram_types_fin, diagram_types_ess  = [\"0_degree\"], []\n",
    "Nfin, Ness = 1900, 1162\n",
    "\n",
    "preprocess_fin = Pipeline([(\"Separator\",     tda.DiagramSelector(limit = np.inf, point_type = \"finite\")),\n",
    "                           (\"ProminentPts\",  tda.ProminentPoints(use = True, num_pts = Nfin)),\n",
    "                           (\"Preprocessor\",  tda.DiagramPreprocessor(use = True, scaler = MinMaxScaler()))\n",
    "                          ])\n",
    "preprocess_ess = Pipeline([(\"Separator\",     tda.DiagramSelector(limit = np.inf, point_type = \"essential\")),\n",
    "                           #(\"Preprocessor\",  tda.DiagramPreprocessor(use = True, scaler = MinMaxScaler()))\n",
    "                          ])\n",
    "\n",
    "num_filt_fin, num_filt_ess = len(diagram_types_fin), len(diagram_types_ess)\n",
    "num_diag_train, num_diag_test, num_diag_full = train_labels.shape[0], test_labels.shape[0], train_full_labels.shape[0]\n",
    "\n",
    "train_D_fin = np.zeros([num_diag_train, num_filt_fin, Nfin, 2]) \n",
    "train_m_fin = np.zeros([num_diag_train, num_filt_fin, Nfin])\n",
    "test_D_fin  = np.zeros([num_diag_test,  num_filt_fin, Nfin, 2]) \n",
    "test_m_fin  = np.zeros([num_diag_test,  num_filt_fin, Nfin]) \n",
    "\n",
    "idx_filt_fin = 0\n",
    "for dt in diagram_types_fin:\n",
    "    \n",
    "    train_full_D = preprocess_fin.fit_transform(train_diag[dt])\n",
    "    train_full_pad_D, train_full_mask = np.zeros([num_diag_full, Nfin, 2]), np.zeros([num_diag_full, Nfin])\n",
    "    for i in range(num_diag_full):\n",
    "        diag = train_full_D[i]\n",
    "        train_full_pad_D[i,:diag.shape[0],:] = diag\n",
    "        train_full_mask[i,:diag.shape[0]] = np.ones([diag.shape[0]])\n",
    "    \n",
    "    if use_fraction_of_train_for_test == True:\n",
    "        train_pad_D, train_mask = train_full_pad_D[train_sub,:], train_full_mask[train_sub,:]\n",
    "        test_pad_D, test_mask = train_full_pad_D[test_sub,:], train_full_mask[test_sub,:]\n",
    "    else:\n",
    "        train_pad_D, train_mask = train_full_pad_D, train_full_mask\n",
    "        test_D = preprocess_fin.fit_transform(test_diag[dt])\n",
    "        test_pad_D, test_mask = np.zeros([num_diag_test, Nfin, 2]), np.zeros([num_diag_test, Nfin])\n",
    "        for i in range(num_diag_test):\n",
    "            diag = test_D[i]\n",
    "            test_pad_D[i,:min(Nfin, diag.shape[0]),:] = diag\n",
    "            test_mask[i,:diag.shape[0]] = np.ones([diag.shape[0]])\n",
    "    \n",
    "    train_D_fin[:,idx_filt_fin,:,:], test_D_fin[:,idx_filt_fin,:,:] = train_pad_D, test_pad_D\n",
    "    train_m_fin[:,idx_filt_fin,:],   test_m_fin[:,idx_filt_fin,:]   = train_mask,  test_mask\n",
    "    idx_filt_fin += 1\n",
    "\n",
    "train_D_ess = np.zeros([num_diag_train, num_filt_ess, Ness, 1]) \n",
    "train_m_ess = np.zeros([num_diag_train, num_filt_ess, Ness])\n",
    "test_D_ess  = np.zeros([num_diag_test,  num_filt_ess, Ness, 1]) \n",
    "test_m_ess  = np.zeros([num_diag_test,  num_filt_ess, Ness]) \n",
    "\n",
    "idx_filt_ess = 0\n",
    "for dt in diagram_types_ess:\n",
    "    \n",
    "    train_full_D = preprocess_ess.fit_transform(train_diag[dt])\n",
    "    train_full_pad_D, train_full_mask = np.zeros([num_diag_full, Ness, 1]), np.zeros([num_diag_full, Ness])\n",
    "    for i in range(num_diag_full):\n",
    "        diag = train_full_D[i]\n",
    "        train_full_pad_D[i,:diag.shape[0],:] = diag\n",
    "        train_full_mask[i,:diag.shape[0]] = np.ones([diag.shape[0]])\n",
    "    \n",
    "    if use_fraction_of_train_for_test == True:\n",
    "        train_pad_D, train_mask = train_full_pad_D[train_sub,:], train_full_mask[train_sub,:]\n",
    "        test_pad_D, test_mask = train_full_pad_D[test_sub,:], train_full_mask[test_sub,:]\n",
    "    else:\n",
    "        train_pad_D, train_mask = train_full_pad_D, train_full_mask\n",
    "        test_D = preprocess_ess.fit_transform(test_diag[dt])\n",
    "        test_pad_D, test_mask = np.zeros([num_diag_test, Ness, 1]), np.zeros([num_diag_test, Ness])\n",
    "        for i in range(num_diag_test):\n",
    "            diag = test_D[i]\n",
    "            test_pad_D[i,:min(Ness, diag.shape[0]),:] = diag\n",
    "            test_mask[i,:diag.shape[0]] = np.ones([diag.shape[0]])\n",
    "    \n",
    "    train_D_ess[:,idx_filt_ess,:,:], test_D_ess[:,idx_filt_ess,:,:] = train_pad_D, test_pad_D\n",
    "    train_m_ess[:,idx_filt_ess,:],   test_m_ess[:,idx_filt_ess,:]   = train_mask,  test_mask\n",
    "    idx_filt_ess += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definition of permutation invariant and equivariant layers. A deep set network is then defined as a combination of such layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def permutation_invariant_layer(inp, dimension):\n",
    "    dimension_before, num_pts = inp.shape[2].value, inp.shape[1].value\n",
    "    with tf.device(\"/cpu:0\"):\n",
    "        #w = tf.get_variable(\"w\",shape=[dimension_before,dimension],initializer=tf.random_uniform_initializer(-1.0,1.0))\n",
    "        #b = tf.get_variable(\"b\",shape=[1,dimension],initializer=tf.random_uniform_initializer(-1.0,1.0))\n",
    "        u, v = 0.5, 0.5\n",
    "        theta = tf.get_variable(\"t\",shape=[1,dimension],initializer=tf.random_uniform_initializer(-np.pi/2,np.pi/2))\n",
    "        cosines, sines = tf.cos(theta), tf.sin(theta)\n",
    "        w, b = tf.concat([cosines,sines],0),tf.get_variable(\"b\",initializer=tf.cast(-u*cosines-v*sines,dtype=tf.float32))\n",
    "    with tf.device(\"/GPU:0\"):\n",
    "        return tf.nn.tanh(tf.reshape(tf.einsum(\"ijk,kl->ijl\", inp, w) + b, [-1, num_pts, dimension]))\n",
    "        \n",
    "def permutation_equivariant_layer(inp, dimension):\n",
    "    dimension_before, num_pts = inp.shape[2].value, inp.shape[1].value\n",
    "    with tf.device(\"/cpu:0\"):\n",
    "        w = tf.get_variable(\"w\",shape=[dimension_before,dimension],initializer=tf.random_uniform_initializer(-1.0,1.0))\n",
    "        b = tf.get_variable(\"b\",shape=[1,dimension],initializer=tf.random_uniform_initializer(-1.0,1.0))\n",
    "    with tf.device(\"/GPU:0\"):\n",
    "        inp_max = tf.tile(tf.reshape(tf.reduce_max(inp, 1), [-1, 1, dimension_before]), [1, num_pts, 1])\n",
    "        l = tf.nn.tanh(tf.einsum(\"ijk,kl->ijl\", inp-inp_max, w) + b)\n",
    "        return tf.layers.batch_normalization(tf.reshape(l,[-1, num_pts, dimension]))\n",
    "    \n",
    "def deep_set_network(ls_dgm, name, diag, mask, weight_mat, perm_inv_layers, perm_eq_layers, keep):\n",
    "    num_diag_t, N = diag.shape[1].value, diag.shape[2].value\n",
    "    for i in range(num_diag_t):\n",
    "        \n",
    "        diag_i, mask_i = diag[:,i,:,:], mask[:,i,:]\n",
    "        weight_i = tf.reshape(tf.einsum(\"ijk,kl->ijl\", diag_i, weight_mat), [-1,N])\n",
    "        \n",
    "        for j in range(len(perm_inv_layers)):\n",
    "            with tf.variable_scope(name + str(i) + \"-perm_inv-\" + str(j)):\n",
    "                diag_i = permutation_invariant_layer(diag_i, perm_inv_layers[i])\n",
    "                \n",
    "        for j in range(len(perm_eq_layers)):\n",
    "            with tf.variable_scope(name + str(i) + \"-perm_eq-\" + str(j)):\n",
    "                diag_i = permutation_equivariant_layer(diag_i, perm_eq_layers[i])\n",
    "    \n",
    "        final_dim                = diag_i.shape[2].value    \n",
    "        tiled_weight_i           = tf.tile(tf.reshape(weight_i, [-1,N,1]), [1,1,final_dim])\n",
    "        tiled_mask_i             = tf.tile(tf.reshape(mask_i,   [-1,N,1]), [1,1,final_dim])\n",
    "        weighted_masked_layer    = tf.multiply(tf.multiply(diag_i, tiled_mask_i), tiled_weight_i)\n",
    "        #weighted_masked_layer    = tf.multiply(diag_i, tiled_mask_i)\n",
    "        weighted_masked_layer_t  = tf.transpose(weighted_masked_layer, perm = [0,2,1])\n",
    "        values, _                = tf.nn.top_k(weighted_masked_layer_t, k = keep)  \n",
    "        \n",
    "        ls_dgm.append(tf.reshape(values, [-1, keep*final_dim]))    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Architecture is multi-channel deep set network followed by a fully connected layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.device(\"/cpu:0\"):\n",
    "    diag_fin = tf.placeholder(tf.float32, shape = [None, len(diagram_types_fin), Nfin, 2],  name = \"finite_diagrams\")\n",
    "    mask_fin = tf.placeholder(tf.float32, shape = [None, len(diagram_types_fin), Nfin],     name = \"finite_masks\")\n",
    "    diag_ess = tf.placeholder(tf.float32, shape = [None, len(diagram_types_ess), Ness, 1],  name = \"essential_diagrams\")\n",
    "    mask_ess = tf.placeholder(tf.float32, shape = [None, len(diagram_types_ess), Ness],     name = \"essential_masks\")\n",
    "    \n",
    "feed_test[diag_fin], feed_train[diag_fin] = test_D_fin, train_D_fin\n",
    "feed_test[mask_fin], feed_train[mask_fin] = test_m_fin, train_m_fin\n",
    "feed_test[diag_ess], feed_train[diag_ess] = test_D_ess, train_D_ess\n",
    "feed_test[mask_ess], feed_train[mask_ess] = test_m_ess, train_m_ess\n",
    "\n",
    "list_diagrams = []\n",
    "deep_set_network(list_diagrams, \"fin\", diag_fin, mask_fin, tf.constant([[-1.0],[1.0]]), [50], [], 99)\n",
    "deep_set_network(list_diagrams, \"ess\", diag_ess, mask_ess, tf.constant([[1.0]]),        [10], [20], 10)\n",
    "\n",
    "# Concatenate all channels\n",
    "vector = tf.concat(list_diagrams, 1)\n",
    "\n",
    "# Fully connected\n",
    "vector = tf.nn.dropout(vector, 0.9)\n",
    "vector = tf.layers.batch_normalization(vector)\n",
    "fn     = tf.layers.dense(vector, num_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Losses and optimization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if task_type == \"classification\":\n",
    "    loss     = tf.reduce_mean(  tf.nn.softmax_cross_entropy_with_logits_v2(labels = label, logits = fn)  )\n",
    "    accuracy = tf.reduce_mean(  tf.cast(tf.equal(tf.argmax(fn,1), tf.argmax(label,1)), dtype = tf.float32)  )\n",
    "    if tensorboard == True:\n",
    "        tf.summary.scalar(\"accuracy\", accuracy)\n",
    "    \n",
    "if task_type == \"regression\":\n",
    "    loss = tf.losses.mean_squared_error(fn, label)\n",
    "\n",
    "if tensorboard == True:\n",
    "    tf.summary.scalar(\"loss\", loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = tf.train.GradientDescentOptimizer(learning_rate = 0.1)\n",
    "train_step = opt.minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if tensorboard == True:\n",
    "    merged = tf.summary.merge_all()\n",
    "\n",
    "print(\"Variables = \" + str(tf.trainable_variables()))\n",
    "print(\"\\nNumber of variables = \" + str(np.sum([np.prod(v.get_shape().as_list()) for v in tf.trainable_variables()])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 Learning best predictor and evaluation on train and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_epoch    = 10000\n",
    "print_every = 100\n",
    "batch_size  = 128\n",
    "plot_lines  = False\n",
    "\n",
    "with tf.Session(config=tf.ConfigProto(log_device_placement=True, allow_soft_placement=True)) as sess:\n",
    "    \n",
    "    if tensorboard == True:\n",
    "        train_writer = tf.summary.FileWriter('./train', sess.graph)\n",
    "        test_writer = tf.summary.FileWriter('./test')\n",
    "    \n",
    "    # Initialize parameters\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "            \n",
    "    # Score to print\n",
    "    if task_type == \"classification\":\n",
    "        score = accuracy\n",
    "    if task_type == \"regression\":\n",
    "        score = loss\n",
    "    \n",
    "    # Learning best predictor\n",
    "    for ep in range(nb_epoch):\n",
    "            \n",
    "        data_epoch = np.random.choice(train_num_pts, batch_size, replace = False)\n",
    "        for k in feed_train.keys():\n",
    "            feed_epoch[k] = feed_train[k][data_epoch]\n",
    "\n",
    "        train_step.run(feed_dict = feed_epoch)\n",
    "            \n",
    "        if ep % print_every == 0: \n",
    "            if tensorboard == True:\n",
    "                train_summary, train_score = sess.run([merged, score], feed_dict = feed_train)\n",
    "                test_summary, test_score = sess.run([merged, score], feed_dict = feed_test)\n",
    "                train_writer.add_summary(train_summary, ep)\n",
    "                test_writer.add_summary(test_summary, ep)\n",
    "            else:\n",
    "                train_score = sess.run(score, feed_dict = feed_train)\n",
    "                test_score  = sess.run(score, feed_dict = feed_test)\n",
    "                \n",
    "            print(\"\\nTrain score on epoch \" + str(ep) + \" = \" + str(train_score))\n",
    "            if use_fraction_of_train_for_test == True:\n",
    "                print(\"Test score on epoch \" + str(ep) + \"  = \" + str(test_score))\n",
    "            \n",
    "            if plot_lines == True:\n",
    "                idx_d, idx_f, num_lines = [0,50,70], 0, 2\n",
    "                b = sess.run(tf.get_collection(tf.GraphKeys.VARIABLES, \"fin\"+str(idx_f)+\"-perm_inv-0/b\")[0])\n",
    "                t = sess.run(tf.get_collection(tf.GraphKeys.VARIABLES, \"fin\"+str(idx_f)+\"-perm_inv-0/t\")[0])\n",
    "                #w = sess.run(tf.get_collection(tf.GraphKeys.VARIABLES, \"fin\"+str(idx_f)+\"-perm_inv-0/w\")[0])\n",
    "                w = np.concatenate([np.cos(t),np.sin(t)],0)\n",
    "                [x1, x2, y1, y2] = [0,1,0,1]\n",
    "                plt.figure()\n",
    "                for idx in idx_d:\n",
    "                    xs, ys = train_D_fin[idx,idx_f,:,0], train_D_fin[idx,idx_f,:,1]\n",
    "                    plt.scatter(xs, ys)\n",
    "                for i in range(num_lines):\n",
    "                    plt.plot([x1,x2],[(-b[0,i]-w[0,i]*x1)/(w[1,i]), (-b[0,i]-w[0,i]*x2)/(w[1,i])])\n",
    "                plt.axis([x1, x2, y1, y2])\n",
    "                plt.show()    \n",
    "            \n",
    "    # Prediction\n",
    "    train_pred, test_pred = sess.run(fn, feed_dict = feed_train), sess.run(fn, feed_dict = feed_test)\n",
    "    if use_fraction_of_train_for_test == False:\n",
    "        np.savetxt(task, test_pred)\n",
    "          \n",
    "    # Evaluation on train set\n",
    "    if use_fraction_of_train_for_test == False:\n",
    "        print(\"\\nTrain score = \" + str(sess.run(score, feed_dict = feed_train)))\n",
    "        if task_type == \"regression\":\n",
    "            plot_regression_result(train_labels, train_pred)\n",
    "        if task_type == \"classification\":\n",
    "            plot_confusion_matrix(confusion_matrix(np.argmax(train_labels,1), np.argmax(train_pred,1)))\n",
    "        \n",
    "    # Evaluation on test set\n",
    "    else:\n",
    "        print(\"Test score  = \" + str(sess.run(score, feed_dict = feed_test)))\n",
    "        if task_type == \"regression\":\n",
    "            plot_regression_result(test_labels, test_pred)\n",
    "        if task_type == \"classification\":\n",
    "            plot_confusion_matrix(confusion_matrix(np.argmax(test_labels,1), np.argmax(test_pred,1)))\n",
    "            \n",
    "    sess.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Aggregating models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_agg, test_agg = np.concatenate(list_train_pred,1), np.concatenate(list_test_pred,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predictor (sklearn, hyperopt)       \n",
    "if task_type == \"classification\" or task_type == \"metric\":\n",
    "    model = RandomForestClassifier()\n",
    "if task_type == \"regression\":\n",
    "    model = LinearRegression()\n",
    "        \n",
    "# Learning best predictor\n",
    "model.fit(train_agg, train_labels)\n",
    "\n",
    "# Prediction\n",
    "train_pred, test_pred = model.predict(train_agg), model.predict(test_agg)\n",
    "\n",
    "# Save predictions\n",
    "if use_fraction_of_train_for_test == False:\n",
    "    np.savetxt(task_name, test_pred)\n",
    "    \n",
    "# Evaluation on train set\n",
    "print(\"Train score = \" + str(model.score(train_agg, train_labels)))\n",
    "if task_type == \"regression\":\n",
    "    print(\"Train MSE = \" + str(mean_squared_error(train_pred, train_labels)))\n",
    "        \n",
    "# Evaluation on test set\n",
    "if use_fraction_of_train_for_test == True:\n",
    "            \n",
    "    print(\"Test score  = \" + str(model.score(test_agg, test_labels)))\n",
    "            \n",
    "    if task_type == \"regression\":\n",
    "        print(\"Test MSE = \" + str(mean_squared_error(test_pred, test_labels)))\n",
    "        plot_regression_result(test_labels, test_pred)\n",
    "                \n",
    "    if task_type == \"classification\":\n",
    "        plot_confusion_matrix(confusion_matrix(test_labels, test_pred))\n",
    "        \n",
    "print(\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
