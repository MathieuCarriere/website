{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy  as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib notebook\n",
    "\n",
    "from sklearn.base            import BaseEstimator, TransformerMixin\n",
    "from sklearn.pipeline        import *\n",
    "from sklearn.preprocessing   import *\n",
    "from sklearn.metrics         import *\n",
    "from sklearn_pandas          import CategoricalImputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataFrameSelector(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, attribute_names):\n",
    "        self.attribute_names = attribute_names\n",
    "    def fit(self, X, y = None):\n",
    "        return self\n",
    "    def transform(self, X):\n",
    "        return X[self.attribute_names].values\n",
    "    \n",
    "class CategoricalEncoder(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        return None\n",
    "    def fit(self, X, y = None):\n",
    "        return self\n",
    "    def transform(self, X):\n",
    "        num_var = X.shape[1]\n",
    "        L = []\n",
    "        for i in range(num_var):\n",
    "            ohe, le = OneHotEncoder(sparse=False), LabelEncoder()\n",
    "            L.append(ohe.fit_transform(np.reshape(le.fit_transform(X[:,i]),(-1,1))))\n",
    "        return np.concatenate(L,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = \"../../../../Documents/datasets/titanic/train.csv\"\n",
    "test_path  = \"../../../../Documents/datasets/titanic/test.csv\"\n",
    "train_data, test_data = pd.read_csv(train_path), pd.read_csv(test_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.hist(bins=50,figsize=(20,15))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.plot(kind=\"scatter\", x=\"Age\", y=\"Fare\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Numerical features\n",
    "num_attribs = [\"Fare\", \"SibSp\", \"Parch\"]\n",
    "# Categorical features\n",
    "cat_attribs = [\"Sex\", \"Embarked\", \"Pclass\"]\n",
    "num_cat_attribs = [2, 2, 4]\n",
    "# Target\n",
    "targets = [\"Survived\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_pipe = Pipeline([(\"selector\",   DataFrameSelector(num_attribs)),  # select\n",
    "                     (\"imputer\",    Imputer(strategy = \"median\")),    # replace missing values (nan) with median\n",
    "                     (\"std_scaler\", StandardScaler())])               # rescale to N(0,1)\n",
    "\n",
    "cat_pipe = Pipeline([(\"selector\",      DataFrameSelector(cat_attribs)),  # select\n",
    "                     (\"imputer\",       CategoricalImputer()),            # replace missing values (nan)\n",
    "                     (\"label_encoder\", CategoricalEncoder()),            # encode to one hot vectors\n",
    "                     (\"std_scaler\",    StandardScaler())])               # rescale to N(0,1)\n",
    "\n",
    "full_pipe = FeatureUnion(transformer_list=[(\"num_pipe\", num_pipe), (\"cat_pipe\", cat_pipe)])\n",
    "train_X, test_X = full_pipe.fit_transform(train_data), full_pipe.transform(test_data)\n",
    "train_X = np.concatenate([DataFrameSelector(targets).fit_transform(train_data), train_X],1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "oh_cat_attribs = []\n",
    "for i in range(len(cat_attribs)):\n",
    "    for j in range(num_cat_attribs[i]):\n",
    "        oh_cat_attribs.append(cat_attribs[i] + str(j))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Writing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "prep_train_data = pd.DataFrame(train_X, columns = targets + num_attribs + oh_cat_attribs)\n",
    "prep_test_data  = pd.DataFrame(test_X,  columns = num_attribs + oh_cat_attribs)\n",
    "\n",
    "train_path = \"../../../../Documents/datasets/titanic/prep_train.csv\"\n",
    "test_path  = \"../../../../Documents/datasets/titanic/prep_test.csv\"\n",
    "\n",
    "prep_train_data.to_csv(train_path)\n",
    "prep_test_data.to_csv(test_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
