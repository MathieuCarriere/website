{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import  sys\n",
    "import  h5py\n",
    "import  numpy              as np\n",
    "import  pandas             as pd\n",
    "import  tensorflow         as tf\n",
    "import  gudhi              as gd\n",
    "import  matplotlib.pyplot  as plt\n",
    "%matplotlib notebook\n",
    "\n",
    "from    features                         import * \n",
    "from    hyperopt                         import *\n",
    "from    hpsklearn                        import *\n",
    "from    sklearn.preprocessing            import *\n",
    "from    sklearn.svm                      import *\n",
    "from    sklearn.ensemble                 import *\n",
    "from    sklearn.decomposition            import *\n",
    "from    sklearn.linear_model             import *\n",
    "from    sklearn.model_selection          import *\n",
    "from    sklearn.pipeline                 import *\n",
    "from    sklearn.manifold                 import *\n",
    "from    sklearn.neighbors                import *\n",
    "from    sklearn.metrics                  import *\n",
    "from    sklearn.metrics.pairwise         import *\n",
    "from    sklearn.feature_selection        import *\n",
    "from    MKLpy.algorithms                 import *\n",
    "from    mpl_toolkits.mplot3d             import Axes3D\n",
    "\n",
    "sys.path.append(\"./layers/rips\")\n",
    "libPDR = tf.load_op_library(\"persistence_diagram_rips.so\")\n",
    "import _persistence_diagram_rips_grad\n",
    "\n",
    "sys.path.append(\"./layers/simplicial\")\n",
    "libPDS = tf.load_op_library(\"persistence_diagram_simplicial_complex.so\")\n",
    "import _persistence_diagram_simplicial_complex_grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pc_to_array(data):\n",
    "\n",
    "    num_pc = len(data.keys())\n",
    "\n",
    "    max_pts = 0\n",
    "    for idx in data.keys():\n",
    "        max_pts = max(max_pts, data[idx].shape[0])\n",
    "    euclidean_dimension = data[\"0\"].shape[1]\n",
    "\n",
    "    dataset = np.full((num_pc, euclidean_dimension * max_pts), np.nan)\n",
    "\n",
    "    for idx in range(num_pc):\n",
    "        point_cloud = np.reshape(np.array(data[str(idx)]), [-1])\n",
    "        dataset[idx, 0:len(point_cloud)] = point_cloud\n",
    "\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Read data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Provide names of different tasks (as in the corresponding .csv file)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tasks = [(\"material\",\"classification\"), (\"sor\",\"regression\")]\n",
    "for i in range(1,13):\n",
    "    tasks.append((\"bin \"+str(i),\"regression\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read train data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_train_feat = \"../../../../Documents/datasets/bridge/7/train.csv\"\n",
    "train_feat = pd.read_csv(path_to_train_feat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_train_clouds = \"../../../../Documents/datasets/bridge/7/train_pc.hdf5\"\n",
    "train_pc = pc_to_list(h5py.File(path_to_train_clouds, \"r\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Specify if test set is 1. a fraction of train set (False) / 2. a separate set with possibly missing labels (True)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_fraction_of_train_for_test = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If test set is fraction of training set, specify ratio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_size = 0.2\n",
    "\n",
    "if use_fraction_of_train_for_test == True:\n",
    "    train_num_pts = train_feat.shape[0]    \n",
    "    perm = np.random.permutation(train_num_pts)\n",
    "    limit = np.int(test_size * train_num_pts)\n",
    "    test_sub, train_sub = np.sort(perm[:limit]), np.sort(perm[limit:]) #perm[:limit], perm[limit:]\n",
    "    train_num_pts, test_num_pts = len(train_sub), len(test_sub)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Else, read test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if use_fraction_of_train_for_test == False:\n",
    "    path_to_test_feat = \"../../../../Documents/datasets/bridge/7/test.csv\"\n",
    "    test_feat = pd.read_csv(path_to_test_feat)\n",
    "    train_num_pts, test_num_pts = train_feat.shape[0], test_feat.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if use_fraction_of_train_for_test == False:\n",
    "    path_to_test_clouds = \"../../../../Documents/datasets/bridge/7/test_pc.hdf5\"\n",
    "    test_pc = pc_to_list(h5py.File(path_to_test_clouds, \"r\"))\n",
    "    train_num_pts, test_num_pts = len(train_pc), len(test_pc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert data frame into numpy array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_F = np.array(train_feat)[:,1+len(tasks):]\n",
    "num_features = train_F.shape[1]\n",
    "\n",
    "if use_fraction_of_train_for_test == False:\n",
    "    test_F = np.array(test_feat)[:,1+len(tasks):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_train_pred, list_test_pred = [], []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = 1500\n",
    "\n",
    "cloud = train_pc[index]\n",
    "kde = KernelDensity(kernel=\"gaussian\", bandwidth=0.7)\n",
    "kde.fit(cloud)\n",
    "vals = kde.score_samples(cloud)\n",
    "fig = plt.figure()\n",
    "ax = Axes3D(fig)\n",
    "ax.scatter(cloud[:,0], cloud[:,1], cloud[:,2], c = vals, cmap ='seismic')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_feat.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Deep Sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reset network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "feed_train, feed_test, feed_epoch = dict(), dict(), dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_name, task_type = tasks[1]\n",
    "\n",
    "ohe, le = OneHotEncoder(sparse = False), LabelEncoder()\n",
    "\n",
    "train_full_labels = train_feat[task_name]\n",
    "if use_fraction_of_train_for_test == True:\n",
    "    train_labels = np.reshape(train_full_labels[train_sub], [-1,1])\n",
    "    test_labels =  np.reshape(train_full_labels[test_sub], [-1,1])\n",
    "else:\n",
    "    train_labels = np.reshape(train_full_labels, [-1,1])\n",
    "    \n",
    "if task_type == \"classification\" or task_type == \"metric\":\n",
    "    train_labels = ohe.fit_transform(np.reshape(le.fit_transform(train_labels), [-1,1]))\n",
    "    if use_fraction_of_train_for_test == True:            \n",
    "        test_labels = ohe.transform(np.reshape(le.transform(test_labels), [-1,1]))\n",
    "\n",
    "num_labels = train_labels.shape[1]\n",
    "label = tf.placeholder(tf.float32, shape = [None, num_labels], name = \"labels\")\n",
    "feed_train[label] = train_labels\n",
    "\n",
    "if use_fraction_of_train_for_test == True:\n",
    "    feed_test[label] = test_labels\n",
    "    \n",
    "print(\"Task: \" + task_name + \" \" + task_type + \", \" + str(num_labels) + \" label(s)\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N, input_dim = 1000, 3\n",
    "\n",
    "preprocess = Pipeline([(\"Preprocessor\",  DiagramPreprocessor(MinMaxScaler()))])\n",
    "\n",
    "train_full_PC = preprocess.fit_transform(train_pc)\n",
    "max_pts, num_pc = 0, len(train_full_PC)\n",
    "for i in range(num_pc):\n",
    "    max_pts = max(max_pts, train_full_PC[i].shape[0])\n",
    "    \n",
    "train_full_pad_PC, train_full_mask = np.zeros([num_pc, max_pts, input_dim]), np.zeros([num_pc, max_pts])\n",
    "for i in range(num_pc):\n",
    "    pc = train_full_PC[i]\n",
    "    train_full_pad_PC[i,:pc.shape[0],:] = pc\n",
    "    train_full_mask[i,:pc.shape[0]] = np.ones([pc.shape[0]])\n",
    "    \n",
    "if use_fraction_of_train_for_test == True:\n",
    "    train_pad_PC, train_mask = train_full_pad_PC[train_sub,:], train_full_mask[train_sub,:]\n",
    "    test_pad_PC, test_mask = train_full_pad_PC[test_sub,:], train_full_mask[test_sub,:]\n",
    "else:\n",
    "    train_pad_PC, train_mask = train_full_pad_PC, train_full_mask\n",
    "    test_full_PC = preprocess.fit_transform(test_pc)\n",
    "    num_pc_test = len(test_full_PC)\n",
    "    test_pad_PC, test_mask = np.zeros([num_pc_test, max_pts, input_dim]), np.zeros([num_pc_test, max_pts])\n",
    "    for i in range(num_pc_test):\n",
    "        pc = test_full_PC[i]\n",
    "        test_pad_PC[i,:min(max_pts,pc.shape[0]),:] = pc\n",
    "        test_mask[i,:pc.shape[0]] = np.ones([pc.shape[0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cloud = tf.placeholder(tf.float32, shape = [None, N, 3], name = \"point clouds\")\n",
    "mask = tf.placeholder(tf.float32, shape = [None, N], name = \"masks\")  \n",
    "feed_test[cloud], feed_train[cloud], feed_test[mask], feed_train[mask] = test_pad_PC, train_pad_PC, test_m, train_m\n",
    "    \n",
    "# Phi network\n",
    "with tf.variable_scope(\"phi\"+str(i), reuse=tf.AUTO_REUSE):\n",
    "\n",
    "    weight1 = tf.get_variable(\"w1\", shape=[3,50], initializer=tf.truncated_normal_initializer(mean=0.0,stddev=0.1))\n",
    "    biases1 = tf.get_variable(\"b1\", shape=[1,50], initializer=tf.truncated_normal_initializer(mean=0.0,stddev=0.1))\n",
    "    phi = tf.reshape(tf.tensordot(cloud, weight1, 1) + biases1, [-1,N,dim1])\n",
    "    final_dim = 50\n",
    "     \n",
    "# Weight and mask\n",
    "tiled_mask = tf.tile(tf.reshape(mask, [-1,N,1]), [1,1,final_dim])\n",
    "masked_phi = tf.multiply(phi, tiled_mask)\n",
    "\n",
    "# Permutation invariant op\n",
    "vector = tf.reduce_sum(masked_phi, 1)\n",
    "\n",
    "# Rho network\n",
    "fn = tf.layers.dense(vector, num_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Losses and optimization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if task_type == \"classification\":\n",
    "    loss     = tf.reduce_mean(  tf.nn.softmax_cross_entropy_with_logits_v2(labels = label, logits = fn)  )\n",
    "    accuracy = tf.reduce_mean(  tf.cast(tf.equal(tf.argmax(fn,1), tf.argmax(label,1)), dtype = tf.float32)  )\n",
    "    tf.summary.scalar(\"accuracy\", accuracy)\n",
    "    \n",
    "if task_type == \"regression\":\n",
    "    loss = tf.losses.mean_squared_error(fn, label)\n",
    "    \n",
    "if task_type == \"metric\":\n",
    "    fn_a, fn_b = tf.expand_dims(fn,0), tf.expand_dims(fn,1)\n",
    "    l2diff = tf.reshape(tf.reduce_sum(tf.square(tf.add(fn_a,-fn_b)),2),[-1,1])\n",
    "    lab = tf.argmax(label,1)\n",
    "    lab_a, lab_b = tf.reshape(lab,[-1,1]), tf.reshape(lab,[1,-1])\n",
    "    neg_pairs = tf.reshape(1.0-1.0*tf.cast(tf.equal(lab_a,lab_b), dtype=tf.float32), [-1,1])\n",
    "    pos_pairs = 1.0-1.0*neg_pairs\n",
    "    loss = tf.reduce_sum(tf.multiply(neg_pairs,tf.nn.relu(1.0-l2diff))) + tf.reduce_sum(tf.multiply(pos_pairs,l2diff))\n",
    "\n",
    "tf.summary.scalar(\"loss\", loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = tf.train.RMSPropOptimizer(learning_rate=0.1)\n",
    "train_step = opt.minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged = tf.summary.merge_all()\n",
    "train_writer = tf.summary.FileWriter('./train', sess.graph)\n",
    "test_writer = tf.summary.FileWriter('./test')\n",
    "\n",
    "print(\"Variables = \" + str(tf.trainable_variables()))\n",
    "print(\"\\nNumber of variables = \" + str(np.sum([np.prod(v.get_shape().as_list()) for v in tf.trainable_variables()])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 Learning best predictor and evaluation on train and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_epoch    = 100\n",
    "print_every = 10\n",
    "batch_size  = 320\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    \n",
    "    # Initialize parameters\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "            \n",
    "    # Score to print\n",
    "    if task_type == \"classification\":\n",
    "        score = accuracy\n",
    "    if task_type == \"regression\" or task_type == \"metric\":\n",
    "        score = loss\n",
    "    \n",
    "    # Learning best predictor\n",
    "    for ep in range(nb_epoch):\n",
    "            \n",
    "        b = np.random.choice(train_num_pts, batch_size, replace = False)\n",
    "        for k in feed_train.keys():\n",
    "            feed_epoch[k] = feed_train[k][b]\n",
    "\n",
    "        train_step.run(feed_dict = feed_epoch)\n",
    "          \n",
    "        if(ep % print_every == 0):\n",
    "            train_summary, train_score = sess.run([merged, score], feed_dict = feed_train)\n",
    "            train_writer.add_summary(train_summary, ep)\n",
    "            test_summary, test_score = sess.run([merged, score], feed_dict = feed_test)\n",
    "            test_writer.add_summary(test_summary, ep)\n",
    "            print(\"\\nTrain score on epoch \" + str(ep) + \" = \" + str(train_score))\n",
    "            if use_fraction_of_train_for_test == True:\n",
    "                print(\"Test score on epoch \" + str(ep) + \"  = \" + str(test_score))\n",
    "            \n",
    "    # Prediction\n",
    "    train_pred, test_pred = sess.run(fn, feed_dict = feed_train), sess.run(fn, feed_dict = feed_test)\n",
    "    if use_fraction_of_train_for_test == False:\n",
    "        np.savetxt(task, test_pred)\n",
    "          \n",
    "    # Evaluation on train set\n",
    "    if use_fraction_of_train_for_test == False:\n",
    "        print(\"\\nTrain score = \" + str(sess.run(score, feed_dict = feed_train)))\n",
    "        if task_type == \"regression\":\n",
    "            plot_regression_result(train_labels, train_pred)\n",
    "        if task_type == \"classification\":\n",
    "            plot_confusion_matrix(confusion_matrix(np.argmax(train_labels,1), np.argmax(train_pred,1)))\n",
    "        if task_type == \"metric\":\n",
    "            dim_red = PCA(n_components = 3)\n",
    "            red = dim_red.fit_transform(train_pred)\n",
    "            trace = go.Scatter3d(x=red[:,0], y=red[:,1], z=red[:,2], mode=\"markers\", \n",
    "                                 marker=dict(size=3, color=np.argmax(train_labels,1), colorscale=\"Viridis\", opacity=0.8))\n",
    "            py.offline.iplot({\"data\": [trace]})\n",
    "        \n",
    "    # Evaluation on test set\n",
    "    else:\n",
    "        print(\"Test score  = \" + str(sess.run(score, feed_dict = feed_test)))\n",
    "        if task_type == \"regression\":\n",
    "            plot_regression_result(test_labels, test_pred)\n",
    "        if task_type == \"classification\":\n",
    "            plot_confusion_matrix(confusion_matrix(np.argmax(test_labels,1), np.argmax(test_pred,1)))\n",
    "        if task_type == \"metric\":\n",
    "            dim_red = PCA(n_components = 3)\n",
    "            red = dim_red.fit_transform(test_pred)\n",
    "            trace = go.Scatter3d(x=red[:,0], y=red[:,1], z=red[:,2], mode=\"markers\", \n",
    "                                 marker=dict(size=3, color=np.argmax(test_labels,1), colorscale=\"Viridis\", opacity=0.8))\n",
    "            py.offline.iplot({\"data\": [trace]})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
